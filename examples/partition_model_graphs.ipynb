{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partitioning Algebraic Graphs\n",
    "__Jordan Jalving and Victor M. Zavala__ <br>\n",
    "__University of Wisconsin-Madison__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/home/jordan/.julia/dev/ModelGraphs/Project.toml\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"/home/jordan/.julia/dev/ModelGraphs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ModelGraphs\n",
    "using JuMP\n",
    "using GLPK\n",
    "using Ipopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the ModelGraph\n",
    "__Here we wreate a ModelGraph and add some nodes__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model Node w/ 0 Variable(s)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mg = ModelGraph()\n",
    "\n",
    "n1 = add_node!(mg)\n",
    "n2 = add_node!(mg)\n",
    "n3 = add_node!(mg)\n",
    "n4 = add_node!(mg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Previously, we showed how you can define variables and constraints directly on ModelNodes.  We can also use JuMP to create our models and then set them to ModelNodes afterwards.  This is helpful if for instance, we want to set a different model onto an existing ModelNode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model Node w/ 1 Variable(s)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set a model on node 1\n",
    "m1 = Model()\n",
    "@variable(m1,0 <= x <= 2)\n",
    "@variable(m1,0 <= y <= 3)\n",
    "@constraint(m1,x+y <= 4)\n",
    "@objective(m1,Min,x)\n",
    "\n",
    "#Set a model on node 2\n",
    "m2 = Model()\n",
    "@variable(m2,x >= 1)\n",
    "@variable(m2,0 <= y <= 5)\n",
    "@NLconstraint(m2,exp(x)+y <= 7)\n",
    "@objective(m2,Min,x)\n",
    "\n",
    "m3 = Model()\n",
    "@variable(m3,x >= 0)\n",
    "\n",
    "m4 = Model()\n",
    "@variable(m4,0 <= x <= 1)\n",
    "\n",
    "\n",
    "#Set models on nodes and edges\n",
    "set_model(n1,m1)     #set m1 to node 1.  Updates reference on m1\n",
    "set_model(n2,m2)\n",
    "set_model(n3,m3)\n",
    "set_model(n4,m4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Link Constraints\n",
    "__Create two link constraints that connect our model nodes.  Underneath, this is actually creating a hypergraph representation of the model (i.e. hyperedges are added when we create link constraints.)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinkConstraintRef(Model Graph:\n",
       "model nodes: 4\n",
       "link variables: 0\n",
       "link constraints: 2\n",
       ", 2, Link edge w/ 1 Constraint(s))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@linkconstraint(mg,n4[:x] == n1[:x])\n",
    "@linkconstraint(mg,n1[:y] + n2[:y] + n3[:x] <= 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hypergraph: (4 , 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypergraph = gethypergraph(mg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypergraph Partitioning\n",
    "__Since we have a hypergraph, we can perform hypergraph partitioning using the KaHyPar Julia Interface__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "using KaHyPar\n",
    "using SparseArrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimize the edge cut subject to balance constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************************************************************************** \n",
      "*                          Top Level Preprocessing..                           * \n",
      "******************************************************************************** \n",
      "Performing community detection: \n",
      "  hypergraph is a graph = false \n",
      "  # communities         = 2 \n",
      "  modularity            = 0.221453 \n",
      "******************************************************************************** \n",
      "*                                Coarsening...                                 * \n",
      "******************************************************************************** \n",
      "Hypergraph Information \n",
      "Name : Coarsened Hypergraph \n",
      "Type: edgeWeights=true nodeWeights=true \n",
      "# HNs : 4 # HEs : 2 # pins: 5 \n",
      "HE size             HE weight           HN degree           HN weight \n",
      "| min= 2            | min= 1            | min= 1            | min= 1           \n",
      "| Q1 = 2            | Q1 = 1            | Q1 = 1            | Q1 = 1           \n",
      "| med= 2            | med= 1            | med= 1            | med= 1           \n",
      "| Q3 = 3            | Q3 = 1            | Q3 = 1            | Q3 = 1           \n",
      "| max= 3            | max= 1            | max= 2            | max= 1           \n",
      "| avg= 2.5          | avg= 1            | avg= 1.25         | avg= 1           \n",
      "| sd = 0.707107     | sd = 0            | sd = 0.5          | sd = 0           \n",
      "\n",
      "******************************************************************************** \n",
      "*                           Initial Partitioning...                            * \n",
      "******************************************************************************** \n",
      "Initial Partitioning Result: \n",
      "Initial cut       = 1 \n",
      "Initial imbalance = 0 \n",
      "Initial part sizes and weights: \n",
      "|part 0 | = 2  w( 0 ) = 2 \n",
      "|part 1 | = 2  w( 1 ) = 2 \n",
      "Target weights:  w(*) = 2 \n",
      "  \n",
      "******************************************************************************** \n",
      "*                               Local Search...                                * \n",
      "******************************************************************************** \n",
      "Local Search Result: \n",
      "Final cut       = 1 \n",
      "Final imbalance = 0 \n",
      "Final part sizes and weights: \n",
      "|part 0 | = 2  w( 0 ) = 2 \n",
      "|part 1 | = 2  w( 1 ) = 2 \n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4-element Array{Int64,1}:\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = sparse(hypergraph)\n",
    "partition1 = KaHyPar.partition(A,2,configuration = :edge_cut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimize connectivity (i.e. communication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************************************************************************** \n",
      "*                          Top Level Preprocessing..                           * \n",
      "******************************************************************************** \n",
      "Performing community detection: \n",
      "  hypergraph is a graph = false \n",
      "  # communities         = 2 \n",
      "  modularity            = 0.221453 \n",
      "******************************************************************************** \n",
      "*                                Coarsening...                                 * \n",
      "******************************************************************************** \n",
      "Hypergraph Information \n",
      "Name : Coarsened Hypergraph \n",
      "Type: edgeWeights=true nodeWeights=true \n",
      "# HNs : 4 # HEs : 2 # pins: 5 \n",
      "HE size             HE weight           HN degree           HN weight \n",
      "| min= 2            | min= 1            | min= 1            | min= 1           \n",
      "| Q1 = 2            | Q1 = 1            | Q1 = 1            | Q1 = 1           \n",
      "| med= 2            | med= 1            | med= 1            | med= 1           \n",
      "| Q3 = 3            | Q3 = 1            | Q3 = 1            | Q3 = 1           \n",
      "| max= 3            | max= 1            | max= 2            | max= 1           \n",
      "| avg= 2.5          | avg= 1            | avg= 1.25         | avg= 1           \n",
      "| sd = 0.707107     | sd = 0            | sd = 0.5          | sd = 0           \n",
      "\n",
      "******************************************************************************** \n",
      "*                           Initial Partitioning...                            * \n",
      "******************************************************************************** \n",
      "Initial Partitioning Result: \n",
      "Initial km1       = 1 \n",
      "Initial imbalance = 0 \n",
      "Initial part sizes and weights: \n",
      "|part 0 | = 2  w( 0 ) = 2 \n",
      "|part 1 | = 2  w( 1 ) = 2 \n",
      "Target weights:  w(*) = 2 \n",
      "  \n",
      "******************************************************************************** \n",
      "*                               Local Search...                                * \n",
      "******************************************************************************** \n",
      "Local Search Result: \n",
      "Final km1       = 1 \n",
      "Final imbalance = 0 \n",
      "Final part sizes and weights: \n",
      "|part 0 | = 2  w( 0 ) = 2 \n",
      "|part 1 | = 2  w( 1 ) = 2 \n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4-element Array{Int64,1}:\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition2 = KaHyPar.partition(A,2,configuration = :connectivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Partitioning\n",
    "__We can also perform graph partitioning if we project the hypergraph into a graph space.  We provide three graph projections to do this.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Metis\n",
    "using NestedHyperGraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  [2, 1]  =  1\n",
      "  [3, 1]  =  1\n",
      "  [4, 1]  =  1\n",
      "  [1, 2]  =  1\n",
      "  [3, 2]  =  1\n",
      "  [1, 3]  =  1\n",
      "  [2, 3]  =  1\n",
      "  [1, 4]  =  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4-element Array{Int32,1}:\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clique_graph,projection_map = clique_expansion(hypergraph)\n",
    "A2 = sparse(clique_graph.lightgraph)\n",
    "println(A2)\n",
    "graph_partition = Metis.partition(A2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bipartite_graph,projection_map = star_expansion(hypergraph)\n",
    "# dual_clique_graph,projection_map = dual_clique_expansion(hypergraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Partitioning Results to the ModelGraph\n",
    "__Use a HyperPartition object to communicate partition information to a ModelGraph.  The idea is that a HyperPartition is a general partitioning interface.  We provide various methods to create HyperPartition objects from common input formats.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperpartition = HyperPartition(hypergraph,partition1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperpartition = HyperPartition(hypergraph,graph_partition,projection_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__With a HyperPartition, we can aggregate a ModelGraph.  Aggregation is necessary to transform a ModelGraph into a standard block-structured form.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_graph,aggregation_map = aggregate(mg,hyperpartition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ModelGraph Solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using ModelGraphSolvers \n",
    "using Distributed\n",
    "\n",
    "dual_decomposition_optimizer = DDOptimizer(workers())\n",
    "optimize!(aggregated_graph,dual_decomposition_optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.3",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
